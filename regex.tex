\documentclass[a4paper,12pt,oneside,onecolumn]{uerj}

\usepackage[brazil]{babel}  % adequacao para o portugues Brasil
\usepackage{cmap}           % Mapear caracteres especiais no PDF
\usepackage[utf8]{inputenc} % Determina a codificacao utiizada
                            % (conversão automática dos acentos)
\usepackage{makeidx}        % Cria o indice
\usepackage{hyperref}       % Controla a formacao do indice
\usepackage{lastpage}       % Usado pela Ficha catalografica
\usepackage{indentfirst}    % Indenta o primeiro paragrafo de cada secao.
\usepackage{color}          % Controle das cores
\usepackage{graphicx}       % Inclusao de graficos
\usepackage{amsmath,amssymb}        % pacote matemático
\usepackage{pdfpages}
\usepackage[top=3cm, bottom=2cm, left=3cm, right=2cm]{geometry}

\usepackage[frame=no,gride=no,algline=yes,font=default]{uerjformat}
\usepackage[alf]{abntcite}
\newcommand{\formato}[1]{\begin{flushleft}{#1}\end{flushleft}}
\newcommand{\BibTeX}{{{Bib}}\TeX}

\logo{uerj/logo_uerj_cinza.png}
\marcadagua{uerj/marcadagua_uerj_cinza.png}{1}{160}{255}


\instituicao{Universidade do Estado do Rio de Janeiro}
            {Centro de Tecnologia e Ciências}
            {Instituto de Matemática e Estatística}
            {Departamento de Informática e Ciência da Computação}

\autor{Juan}{Lopes}
\titulo{Uma Implementação de Expressões Regulares em PTIME}

\orientador{Prof} % rotulo
           {Paulo Eustáquio Duarte}{Pinto} % {nome}{sobrenome}
           {[afiliação]} % afiliacao

\coorientador{titulação} % rotulo
           {[nome de]}{[sobrenome]} % {nome}{sobrenome}
           {[afiliação]} % afiliacao


\grau{Bacharel}
\curso{Informática e Tecnologia da Informação}

\local{Rio de Janeiro}   % cidade
\data{17}{Maio}{2013} % {dia}{mes}{ano}

% *****************************************************************************
% *****************************************************************************
% Configurações de aparência do PDF final
% *****************************************************************************
% *****************************************************************************

% alterando o aspecto da cor azul
%\definecolor{blue}{RGB}{41,5,195}

% informações do PDF
\hypersetup{
  %backref=true,
  %pagebackref=true,
  %bookmarks=true,                  % show bookmarks bar?
  pdftitle={\UERJtitulo},
  pdfauthor={\UERJautor},
  pdfsubject={\UERJpreambulo},
  pdfkeywords={Expressões Regulares}{Regex}{Autômatos Finitos},
  pdfproducer={LaTeX with class repUERJ}, % producer of the document
  pdfcreator={\UERJautor},
  colorlinks=true,                  % false: boxed links; true: colored links
  linkcolor=blue,                   % color of internal links blue
  citecolor=blue,                    % color of links to bibliography blue
  filecolor=blue,                % color of file links magenta
  urlcolor=blue,
  bookmarksdepth=4
}

\makeindex

\begin{document}

\frontmatter
\capa
\folhaderosto

%\includepdf{ficha_catalografica.pdf}

\begin{folhadeaprovacao}
  \assinatura{titulação membro1\\ afiliação1}
\end{folhadeaprovacao}

\pretextualchapter{Dedicatória}

  \vfill\vfill
    \hfill À minha esposa, Jacqueline.
  \vfill


% ----------------------------------------------------------
% Epigrafe
% ----------------------------------------------------------

\pretextualchapter{}

  \vfill\vfill\vfill\vfill
  \begin{flushright}
     Simplicity is a great virtue but it requires hard work\\
     to achieve it and education to appreciate it. And to \\
     make matters worse: complexity sells better.\\
    \textsl{-- Edsger W. Dijkstra}
  \end{flushright}
  \vfill

% ----------------------------------------------------------
% RESUMO
% ----------------------------------------------------------

\pretextualchapter{Resumo}

\refbibliografica

Na teoria, expressões regulares constituem uma notação para definir linguagens regulares em termos de operações recursivas simples. São equivalentes a autômatos finitos em seu poder expressivo. Na prática entretanto, enquanto ferramentas extremamente populares, as expressões regulares modernas afastaram-se bastante da teoria que as originou. 

A maior parte das mudanças aconteceu para permiti-las alcançar um poder de expressão maior. Entretanto, esta conveniência veio a custo de tornar o \emph{match} um problema mais difícil computacionalmente do que a teoria descreve. Na maior parte das linguagens modernas o \emph{match} de \emph{regexes} (como são comumente conhecidas) é um problema NP-completo. Além disso, por particularidades de como são implementadas, mesmo expressões que poderiam ser reconhecidas em tempo polinomial são resolvidas com soluções exponenciais. 

Este trabalho visa analisar as armadilhas comuns no desenvolvimento de expressões regulares, realizando benchmarks entre diversas implementações populares, apontando funcionalidades que impediriam sua execução polinomial. Também sugere uma implementação simples e didática que tem desempenho em pior caso ordens de grandeza superior às bibliotecas-padrão de muitas linguagens.

\noindent {Palavras-chave}: Teoria da computação. Expressões regulares. Linguagens regulares. Autômatos finitos. Complexidade computacional. Algoritmos. NP-completo.

% ----------------------------------------------------------
% Abstract
% ----------------------------------------------------------

\pretextualchapter{Abstract}

In theory, regular expressions are a notation to define regular languages in terms of simple recursive operations. Are equivalent to finite automata in its expressive power. In practice however, while very popular tools, modern regular expressions did deviate from the theory that gave them origin.

Most of the changes happened to allow them to reach a greater expressive power. This convenience, however came at the cost of making the match a computationally harder problem than what theory describes. In most of the modern languages, the regex match (as it is commonly known) is a NP-complete problem. Besides, the way they are implemented makes even expressions that could be recognized in polynomial time to be solved with exponential algorithms.

This work aims to analyze the common pitfalls in regular expressions development, measuring performance with benchmarks of the most popular implementations, pointing the features that could not be implemented in polynomial time. Also it suggests a simple and didactic implementation which has superior worst-case performance than many language's standard libraries.

\noindent {Keywords}: Computation theory. Regular expressions. Regular languages. Finite automata. Computational complexity. Algorithms. NP-complete.

\listadefiguras
%\listadetabelas

\sumario

\mainmatter

%======================================================================================
\chapter{Introdução}
%======================================================================================

Neste capítulo serão apresentados a motivação, objetivos, e a estrutura do projeto.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\section{Motivação}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Expressões regulares fazem parte do ferramental da maioria das linguagens e plataformas de desenvolvimento modernas. Seu uso é bastante difundido na indústria para os mais variados fins, desde o reconhecimento de padrões, passando pela extração de símbolos para análise sintática de linguagens formais, até a sanitização de entradas do usuário para fins de segurança.

Seu extensivo uso vem precedido por uma forte base teórica na área de autômatos finitos, introduzida nos anos 40 por McCulloch e Pitts \cite{bib:McCulloch43}, formalizada na década seguinte por Kleene \cite{bib:Kleene56} e implementada por Ken Thompson no final dos anos 60 \cite{bib:Thompson68}, enquanto desenvolvia o editor de texto \emph{QED}, posteriormente portada para os mais conhecidos \emph{ed} e \emph{grep}, integrantes do sistema operacional Unix.

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.25]{figures/exemplo_automato.png}
  \caption{Exemplo de autômato para expressão regular $(a|b)+c$}
\end{figure}

Desde então, conforme as implementações foram evoluindo, muitas funcionalidades foram adicionadas à linguagem de descrição de expressões regulares que as afastaram da teoria original. Enquanto originalmente descreviam linguagens estritamente regulares, a implementação mais difundida atualmente (\emph{PCRE}) é capaz não só de reconhecer qualquer linguagem livre de contexto, como também algumas sensíveis a contexto. \cite{bib:Nikita12}

Uma das consequências mais notáveis desta evolução não planejada é que o reconhecimento de strings da linguagem, um problema com solução linear originalmente, ganhou soluções exponenciais em um grande número de implementações modernas, que inclui muitas das mais usadas. Talvez a funcionalidade mais perigosa neste sentido sejam as backreferences, que não só impedem soluções polinomiais como tornam o problema de reconhecimento NP-completo. Entretanto, mesmo nas expressões que poderiam ser reconhecidas estritamente com autômatos finitos, certas particularidades de implementação as tornam potencialmente exponenciais, no pior caso. \cite{bib:Cox07}

Essas implementações tornam o uso de expressões regulares potencialmente inseguro em situações ora triviais. Um usuário mal intencionado pode ser capaz de forçar a execução de uma expressão com caráter exponencial para efetuar um ataque de negação de serviço em um servidor web, por exemplo. Muitas vezes a prevenção para esse tipo de ataque pode não ser trivial, e.g. em Java, onde métodos comumente usados contra a entrada do usuário, como \emph{replaceAll} e \emph{split}, da classe \emph{String} são implementados usado expressões regulares vulneráveis a esse tipo de ataque.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\section{Objetivo}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Este projeto tem dois objetivos principais. O primeiro é demonstrar através de testes pontuais e benchmarks os problemas fundamentais nas implementações de expressões regulares em diversas linguagens modernas, provando inclusive a NP-completude do problema de reconhecimento de strings nas linguagens que definem. O segundo objetivo é propor uma implementação didática e minimalista das expressões regulares propostas por Kleene, utilizando o método descrito por Thompson para construção e simulação do autômato. 

A implementação irá deixar de fora certas funcionalidades comuns nos \emph{sabores} mais modernos de expressão regular. Algumas destas funcionalidades podem ser implementadas sem sacrificar eficiência de execução. Outras, introduzem certa complexidade, porém mantendo a execução do algoritmo polinomial. O restante, entretanto, não é possível implementar sem tornar o algoritmo exponencial no pior caso. Todas as funcionalidades intencionalmente excluídas serão listadas e propostas de soluções serão apresentadas quando cabível.

Deseja-se mostrar com esse projeto que o problema de reconhecimento de expressões regulares pode ser resolvido de maneira eficiente, mesmo com as implementações mais simples, desde que seja observada a base teórica que as deu origem.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\section{Estrutura}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

O projeto está divido em cinco capítulos. O capítulo 2 trata da base teórica por trás das expressões regulares, contando sua história, passando pelo método de construção do autômato de Thompson, e exibindo um algoritmo trivial (porém ineficiente) para sua solução.

O capítulo 3 descreve poder das implementações modernas de expressão regular, mostrando recursos avançados, como \emph{zero-width assertions} e \emph{backreferences}. Mostra também exemplos de expressões que reconhecem gramáticas não-regulares, exibindo o distanciamento entre estas e a teoria original. Por fim, é mostrado um benchmark comparando a performance entre as diversas implementações, que evidenciam uma diferença fundamental na forma como o problema é abordado em cada uma delas.

No capítulo 4 é proposta uma implementação de expressões regulares utilizando o método de Thompson. Os resultados teóricos e práticos desta implementação são discutidos e comparados com resultados anteriores.

O capítulo 5 expõe as conclusões e contribuições deste trabalho, bem como as dificuldades encontradas durante o projeto. Também serão listadas e descritas as funcionalidades não implementadas, possivelmente sugerindo formas eficientes de implementá-las, ou mesmo formas diferentes de simular o autômato que melhorem a eficiência geral da execução.

%======================================================================================
\chapter{Base Teórica}
%======================================================================================

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\section{Hierarquia de Chomsky}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Segundo Noam Chomsky \cite{bib:Chomsky57}, uma linguagem formal pode ser classificada em um de quatro tipos baseados na capacidade expressiva das gramáticas formais que a expressam:

\begin{lcircp}
    \item {\bf Tipo 0}: linguagens recursivamente enumeráveis (ou irrestritas)
    \item {\bf Tipo 1}: linguagens sensíveis a contexto
    \item {\bf Tipo 2}: linguagens livres de contexto
    \item {\bf Tipo 3}: linguagens regulares
\end{lcircp}

Cada conjunto é propriamente incluso no seu conjunto superior na hierarquia, como pode ser visto na Figura ~\ref{fig:chomsky}.

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.5]{figures/chomsky.png}
  \caption{Representação da inclusão de conjuntos na hiearquia de Chomsky}
  \label{fig:chomsky}
\end{figure}

{\bf Linguagens regulares} são aquelas cujas regras de formação são na forma $S \rightarrow aT$ ou $S \rightarrow a$, onde \emph{S} e \emph{T} são não-terminais e \emph{a} é um terminal na linguagem. Estas linguagens são equivalentes em poder de expressão a \emph{autômatos finitos}. Exemplos: $a^n$, $a^nb^m$.

{\bf Linguagens livres de contexto} são linguagens onde todas as regras de formação são do tipo $S \rightarrow \gamma$, onde $\gamma$ é uma sequência composta por terminais e não-terminais. Isto na prática significa que a substituição de um não-terminal é sempre feita independente do contexto onde é encontrado. Linguagens deste tipo são equivalentes em poder expressivo a \emph{autômatos de pilha}. Elas compõem a base teórica para a maioria das linguagens de programação. Exemplos: \emph{parênteses aninhados}, $a^nb^n$.

{\bf Linguagens sensíveis a contexto} são linguagens onde todas as regras de formação são do tipo $\alpha S\beta\rightarrow \alpha\gamma\beta$, onde $\alpha$, $\gamma$ e $\beta$ são sequências compostas por terminais e não-terminais. Elas diferem das linguagens livres de contexto por definir -- exatamente -- contexto para que um não-terminal S seja substituído por uma sequência $\gamma$. Apesar de terem um escopo bem mais amplo, gramáticas deste tipo ainda são passíveis de ser computadas usando um \emph{autômato linearmente limitado}. Exemplos: \emph{squares} (\emph{DogDog, CatCat, WikiWiki}), $a^nb^nc^n$.

{\bf Linguagens recursivamente enumeráveis} não definem restrições para as regras de produção. Portanto, qualquer sequência de terminais e não-terminais $\alpha$ pode ser substituída por outra $\beta$. Linguagens assim são reconhecíveis por uma \emph{máquina de Turing}. Entretanto, diferente dos tipos anteriores, quando apresentada a uma sequência que não faça parte da linguagem, não há garantia de parada da máquina, definindo o que é chamado na teoria de conjunto \emph{semi-decidível}.


%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\section{Expressões regulares}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Expressões regulares são sequências de caracteres que definem linguagens regulares. Estas sequências obedecem a algumas regras de criação. Alguns caracteres são interpretados literalmente, enquanto outros são considerados metacaracteres que controlam como os trechos da expressão se relacionam.

Por definição:

\begin{lcircp}
    \item Sequências vazias são expressões regulares.
    \item Caracteres unitários são expressões regulares. E.g. \emph{a}.
    \item Expressões regulares podem ser concatenadas para formar novas expressões. E.g. se $e_1$ reconhece \emph{a} e $e_2$ reconhece \emph{b}, então $e_1e_2$ reconhece \emph{ab}.
    \item Expressões regulares podem ser alternadas para formar novas expressões. E.g. se $e_1$ reconhece \emph{a} e $e_2$ reconhece \emph{b}, então $e_1|e_2$ reconhece \emph{a} e \emph{b}.
    \item Pode-se aplicar o fecho Kleene para formar novas expressões. E.g. se $e_1$ reconhece \emph{a}, então $e_1*$ reconhece \emph{a}, \emph{aa}, \emph{aaa}... etc., bem como string vazia.
\end{lcircp}

Perceba que é possível definir outros operadores comuns, como $?$ e $+$. Mas é possível fazê-lo a partir das operações descritas acima. O operador $e_1?$ pode ser definido como a alternância entre $e_1$ e uma string vazia. O operarador $e_1+$ pode ser definido como $e_1e_1*$.

Outros operadores sobre caracteres como o $.$ (qualquer caractere) e as classes de caractere (e.g. $[a-zA-Z]$) são trivialmente implementados usando alternação de expressões.

A precedência natural dos operadores, da mais fraca para a mais forte, é: alternância, concatenação, repetição. Assim, uma expressão como $ab|cd*$ é interpretada como exibido na Figura ~\ref{fig:abcd_parse_tree}.

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.4]{figures/abcd_parse_tree.png}
  \caption{Árvore de avaliação para expressão $ab|cd*$}
  \label{fig:abcd_parse_tree}
\end{figure}

É possível agrupar sub-expressões utilizando parênteses, tal qual é feito com expressões aritméticas. Assim $a(b|c)d*$ tem um sentido completamente diferente de $ab|cd*$.

Estas operações, apesar de bastante incompletas, definem inequivocamente expressões regulares. É possível representar qualquer linguagem regular utilizando apenas estes operadores. Mais importante: é teóricamente possível reconhecer qualquer sequência nesta linguagem com apenas uma passagem pela entrada (sem \emph{backtracking}). 

Novas implementações de expressões regulares adicionaram novos operadores que tornam a sintaxe mais concisa. Porém, essas adições normalmente não alteram o poder expressivo das regexes. No entanto, existem adições que adicionam poder expressivo, como é o caso das \emph{backreferences}, que permitem o reconhecimento de algumas linguagens não-regulares. \emph{Backreferences} consiste em referências \emph{submatches} reconhecias anteriormente.

Por exemplo, uma linguagem composta por sequências de caracteres repetidas, como \emph{DogDog} ou \emph{CatCat}. É possível definir uma expressão regular $/(.*)\backslash 1/$ que reconhece esta linguagem. o $\backslash 1$ instrui ao motor de reconhecimento a esperar uma nova sequência exatamente igual à obtida pelo reconhecimento do primeiro grupo $(.*)$.

Esta linguagem não apenas cai fora do conjunto das linguagens regulares, como também não é uma linguagem livre de contexto.

Tal poder expressivo tem seu preço. Match de backreferences é um problema NP-completo, logo, os melhores algoritmos conhecidos ainda tem pior caso exponencial. É possível, porém, escrever algoritmos polinomiais para expressões que não fazem uso de backreferences. No entanto, pela diferente natureza dos dois tipos de algoritmos, normalmente as linguagens implementam apenas um deles, fazendo com que algumas expressões que originalmente poderiam ser avaliadas em tempo polinomial serem penalizadas sem necessidade.

\backmatter
%\citeoption{abnt-options4}
\bibliography{bibliografia}

\end{document}

